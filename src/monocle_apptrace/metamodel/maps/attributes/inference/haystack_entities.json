{
  "type": "inference",
  "attributes": [
    [
      {
        "_comment": "provider type ,name , deployment , inference_endpoint",
        "attribute": "type",
        "accessor": "lambda instance,args,kwargs,return_value:'inference.azure_oai'"
      },
      {
        "attribute": "provider_name",
        "accessor": "lambda instance,args,kwargs,return_value:kwargs['provider_name']"
      },
      {
        "attribute": "deployment",
        "accessor": "lambda instance,args,kwargs,return_value: resolve_from_alias(instance.__dict__, ['engine', 'azure_deployment', 'deployment_name', 'deployment_id', 'deployment'])"
      },
      {
        "attribute": "inference_endpoint",
        "accessor": "lambda instance,args,kwargs,return_value: resolve_from_alias(instance.__dict__, ['azure_endpoint', 'api_base'])  or kwargs['inference_endpoint']"
      }
    ],
    [
      {
        "_comment": "LLM Model",
        "attribute": "name",
        "accessor": "lambda instance,args,kwargs,return_value: resolve_from_alias(instance.__dict__, ['model', 'model_name'])"
      },
      {
        "attribute": "type",
        "accessor": "lambda instance,args,kwargs,return_value: 'model.llm.'+resolve_from_alias(instance.__dict__, ['model', 'model_name'])"
      }
    ]
  ]
}
